# -*- coding: utf-8 -*-
import os, math, csv, json, requests, time # åŒ¯å…¥å¿…è¦æ¨¡çµ„
from flask import Flask, request, jsonify # åŒ¯å…¥ Flask ç›¸é—œ
from flask_cors import CORS # è™•ç†è·¨ä¾†æºè«‹æ±‚
from functools import lru_cache # ç”¨æ–¼å¿«å– Geocoding çµæœ

# ---------------------------
# åŸºæœ¬è¨­å®š
# ---------------------------
app = Flask(__name__)
CORS(app) # å…è¨±æ‰€æœ‰ä¾†æºçš„å‰ç«¯å‘¼å«

# --- è·¯å¾‘è¨­å®š ---
# å‡è¨­ data è³‡æ–™å¤¾èˆ‡ app.py åœ¨åŒä¸€å±¤ç´š (ä¾‹å¦‚éƒ½åœ¨ backend è³‡æ–™å¤¾å…§)
DATA_DIR = "data" 
GEOCODE_CACHE_FILE = os.path.join(DATA_DIR, "geocode_cache.json")
# ã€ã€ã€é‡è¦ã€‘ã€‘ã€‘ å‡è¨­ CSV æª”æ¡ˆèˆ‡ app.py åœ¨åŒä¸€å±¤ç´š
STORES_CSV_FILE = "å…¨åœ‹5å¤§è¶…å•†è³‡æ–™é›†.csv" 
# é è™•ç†å¾Œçš„å°åŒ—ä¾¿åˆ©å•†åº—æª”æ¡ˆè·¯å¾‘
STORES_TAIPEI_CSV = os.path.join(DATA_DIR, "stores_taipei.csv") 
os.makedirs(DATA_DIR, exist_ok=True) # ç¢ºä¿ data ç›®éŒ„å­˜åœ¨

# --- API é‡‘é‘°èˆ‡ç¶²å€ ---
# ã€ã€ã€é—œéµï¼ï¼ï¼ã€‘ã€‘ã€‘ è«‹åœ¨æ­¤è™•è²¼ä¸Šæ‚¨å®‰å…¨çš„ Google API é‡‘é‘°
# (æ­£å¼éƒ¨ç½²æ™‚ï¼Œå¼·çƒˆå»ºè­°æ”¹ç”¨ç’°å¢ƒè®Šæ•¸ï¼)
GOOGLE_MAPS_API_KEY = os.environ.get("GOOGLE_MAPS_API_KEY", "ã€è«‹åœ¨é€™è£¡è²¼ä¸Šæ‚¨å®‰å…¨çš„Google_APIé‡‘é‘°ã€‘")
# --- --- --- --- --- --- --- --- --- --- --- ---
GEOCODING_API_URL = "https://maps.googleapis.com/maps/api/geocode/json"
TAIPEI_POLICE_API_URL = "https://data.taipei/api/v1/dataset/a90ae184-c39e-4242-b2d6-d7a0403c0632?scope=resourceAquire"

# é è™•ç†æ™‚æœ€å¤š Geocode å¤šå°‘ç­†ä¾¿åˆ©å•†åº— (None=ä¸é™åˆ¶ï¼Œè¨­æ•¸å­—å¯åŠ é€Ÿå•Ÿå‹•)
TAIPEI_BUILD_LIMIT = None 

# ---------------------------
# å…¬ç”¨å‡½å¼ (æ‚¨çš„ç‰ˆæœ¬)
# ---------------------------
def get_distance(lat1, lon1, lat2, lon2):
    R = 6371.0; try: lat1, lon1, lat2, lon2 = map(float, [lat1, lon1, lat2, lon2]); dLat = math.radians(lat2 - lat1); dLon = math.radians(lon2 - lon1); a = math.sin(dLat / 2)**2 + math.cos(math.radians(lat1)) * math.cos(math.radians(lat2)) * math.sin(dLon / 2)**2; return R * 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a)); except: return float("inf")

def normalize_text(t: str) -> str:
    if not t: return ""; t = ''.join(chr(ord(c) - 0xFEE0) if 0xFF01 <= ord(c) <= 0xFF5E else c for c in t); return t.replace(" ", "").replace("t", "").lower()

# ---------------------------
# Geocoding å¿«å– (æ‚¨çš„ç‰ˆæœ¬ï¼Œç¨ä½œå„ªåŒ–)
# ---------------------------
try:
    with open(GEOCODE_CACHE_FILE, "r", encoding="utf-8-sig") as f: # æ”¹ç”¨ utf-8-sig
        GEO_CACHE = json.load(f)
    print(f"âœ… Geocode å¿«å–è¼‰å…¥æˆåŠŸï¼Œå…± {len(GEO_CACHE)} ç­†è¨˜éŒ„ã€‚")
except Exception:
    GEO_CACHE = {}; print("â„¹ï¸ æœªæ‰¾åˆ°æˆ–ç„¡æ³•è®€å– Geocode å¿«å–æª”æ¡ˆï¼Œå°‡å»ºç«‹æ–°çš„å¿«å–ã€‚")

def save_cache():
    try:
        with open(GEOCODE_CACHE_FILE, "w", encoding="utf-8") as f:
            json.dump(GEO_CACHE, f, ensure_ascii=False, indent=2)
    except Exception as e: print(f"âŒ å„²å­˜ Geocode å¿«å–å¤±æ•—: {e}")

# ---------------------------
# æ™ºæ…§ Geocodeï¼ˆæ‚¨çš„ç‰ˆæœ¬ï¼Œç¨ä½œå„ªåŒ–ï¼‰
# ---------------------------
@lru_cache(maxsize=512) # ä½¿ç”¨å…§å»ºå¿«å–ï¼Œå¢åŠ å¤§å°
def geocode(address: str):
    if not address: return None
    address = address.strip() # å¢åŠ  strip
    if address in GEO_CACHE: return GEO_CACHE[address]
    
    # æª¢æŸ¥é‡‘é‘°
    api_key_valid = GOOGLE_MAPS_API_KEY and not GOOGLE_MAPS_API_KEY.startswith("ã€è«‹åœ¨é€™è£¡")
    if not api_key_valid:
        if not hasattr(geocode, 'api_key_warning_printed'): print("âŒ Geocode éŒ¯èª¤ï¼šæœªè¨­å®šæœ‰æ•ˆ Google API é‡‘é‘°"); geocode.api_key_warning_printed = True
        return None

    # Step 1: æ¸…ç†åœ°å€ (æ‚¨çš„é‚è¼¯)
    clean = address.replace("ã€€", "").replace(" ", "")
    for token in ["åœ°ä¸‹ä¸€å±¤","åœ°ä¸‹1æ¨“","åœ°ä¸‹äºŒæ¨“","B1","B2","B3","1æ¨“","2æ¨“","3æ¨“","4æ¨“","5æ¨“","6æ¨“"]: clean = clean.replace(token, "")
    for sep in ["ã€", "ï¼Œ", ","]: 
        if sep in clean: clean = clean.split(sep)[0]
    clean = clean.replace("ä¹‹", "")
    
    # Step 2: å‘¼å« Google API (æ‚¨çš„é‚è¼¯)
    def query_google(addr):
        if not addr: return None # å¢åŠ ç©ºåœ°å€æª¢æŸ¥
        print(f"  Geocoding API Call: {addr[:40]}...") # å¢åŠ æ—¥èªŒ
        try:
            r = requests.get(GEOCODING_API_URL, params={ "address": addr, "key": GOOGLE_MAPS_API_KEY, "language": "zh-TW", "region": "tw", "components": "country:TW" }, timeout=8)
            r.raise_for_status(); data = r.json()
            if data.get("status") == "OK" and data.get("results"):
                loc = data["results"][0]["geometry"]["location"]; return {"lat": loc["lat"], "lng": loc["lng"]}
            else: # æ›´è©³ç´°çš„éŒ¯èª¤æ—¥èªŒ
                status = data.get('status', 'æœªçŸ¥'); error_msg = data.get('error_message', '')
                if status == 'ZERO_RESULTS': print(f"  âš ï¸ Geocode æŸ¥ç„¡çµæœ for: {addr}")
                else: print(f"  âŒ Geocode å¤±æ•— for: {addr} ({status} - {error_msg})")
        except requests.exceptions.Timeout: print(f"  âŒ Geocode éŒ¯èª¤: {addr} => è«‹æ±‚è¶…æ™‚")
        except requests.exceptions.RequestException as e: print(f"  âŒ Geocode éŒ¯èª¤: {addr} => ç¶²è·¯è«‹æ±‚å¤±æ•— - {e}")
        except Exception as e: print(f"  âŒ Geocode éŒ¯èª¤: {addr} => æœªé æœŸéŒ¯èª¤ - {e}")
        return None

    # Step 3: å…ˆè©¦åŸå§‹ â†’ å†è©¦ç°¡åŒ– (æ‚¨çš„é‚è¼¯)
    coords = query_google(address)
    if not coords and clean != address: # åªæœ‰åœ¨æ¸…ç†å¾Œåœ°å€ä¸åŒæ™‚æ‰é‡è©¦
        print(f"  > åŸå§‹åœ°å€å¤±æ•—ï¼Œå˜—è©¦æ¸…ç†å¾Œåœ°å€: {clean[:40]}...")
        coords = query_google(clean)
        if coords: print(f"  âœ… ç°¡åŒ–å¾ŒæˆåŠŸ!")
        else: print(f"  âš ï¸ ç°¡åŒ–å¾Œä»å¤±æ•—")
    elif coords: print(f"  âœ… Geocode æˆåŠŸ (åŸå§‹)")
    else: print(f"  âš ï¸ Geocode å¤±æ•— (åŸå§‹)") # å¦‚æœåŸå§‹åœ°å€å°±æ˜¯ç©ºçš„æˆ–æŸ¥è©¢å¤±æ•—

    GEO_CACHE[address] = coords # ç„¡è«–æˆåŠŸ(coords)æˆ–å¤±æ•—(None)éƒ½å­˜å…¥å¿«å–
    save_cache()
    return coords

# ---------------------------
# å“ç‰Œåµæ¸¬ (æ‚¨çš„ç‰ˆæœ¬)
# ---------------------------
def detect_brand(company: str, name: str) -> str: # åŠ å…¥ name åƒæ•¸
    text_to_check = f"{company} {name}".lower().replace(" ", "").replace("è‚¡ä»½æœ‰é™å…¬å¸","")
    if not text_to_check: return "å…¶ä»–"
    if any(k in text_to_check for k in ["çµ±ä¸€è¶…å•†", "7-eleven", "seven-eleven"]): return "7-ELEVEN"
    if "å…¨å®¶" in text_to_check or "familymart" in text_to_check: return "å…¨å®¶"
    if "å…¨è¯" in text_to_check or "px mart" in text_to_check or "pxmart" in text_to_check: return "å…¨è¯"
    if "èŠçˆ¾å¯Œ" in text_to_check or "hi-life" in text_to_check: return "èŠçˆ¾å¯Œ"
    if "ä¾†ä¾†è¶…å•†" in text_to_check or "ok mart" in text_to_check or "okmart" in text_to_check: return "OK mart"
    return "å…¶ä»–"

# ---------------------------
# ç”¢ç”Ÿå°åŒ—åº—èˆ–æª” (æ‚¨çš„ç‰ˆæœ¬ï¼Œä¿®æ­£è·¯å¾‘å’ŒéŒ¯èª¤è™•ç†)
# ---------------------------
def ensure_taipei_stores():
    print("\nâ³ é–‹å§‹é è™•ç†å°åŒ—å¸‚ä¾¿åˆ©å•†åº—è³‡æ–™...")
    start_time = time.time()
    
    # ã€ä¿®æ­£ã€‘ç›´æ¥ä½¿ç”¨æª”åï¼Œå‡è¨­ CSV èˆ‡ app.py åŒç›®éŒ„
    if not os.path.exists(STORES_CSV_FILE): 
        print(f"âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°ä¾†æº CSV æª”æ¡ˆ '{STORES_CSV_FILE}'")
        return {"ok": False, "error": "Source CSV not found"}
        
    rows = []
    try:
        with open(STORES_CSV_FILE, "r", encoding="utf-8-sig", newline='') as f: # ä½¿ç”¨ utf-8-sig
             # è‡ªå‹•åµæ¸¬æ ¼å¼
            try: sample = f.read(4096); dialect = csv.Sniffer().sniff(sample, delimiters=',\t'); f.seek(0); reader = csv.DictReader(f, dialect=dialect)
            except csv.Error: print("âš ï¸ CSV Sniffer å¤±æ•—ï¼Œä½¿ç”¨é è¨­æ ¼å¼"); f.seek(0); reader = csv.DictReader(f)
            
            # æª¢æŸ¥å¿…è¦æ¬„ä½
            required_cols = ["åˆ†å…¬å¸åœ°å€", "åˆ†å…¬å¸åç¨±", "å…¬å¸åç¨±"]
            if not reader.fieldnames or not all(col in reader.fieldnames for col in required_cols):
                 print(f"âŒ éŒ¯èª¤ï¼šCSV ç¼ºå°‘å¿…è¦æ¬„ä½ {required_cols}ã€‚åµæ¸¬åˆ°çš„æ¬„ä½: {reader.fieldnames}")
                 return {"ok": False, "error": "Missing required CSV columns"}

            for i, row in enumerate(reader):
                try:
                    addr = (row.get("åˆ†å…¬å¸åœ°å€") or "").strip()
                    name = (row.get("åˆ†å…¬å¸åç¨±") or "").strip() 
                    company = (row.get("å…¬å¸åç¨±") or "").strip()
                    display_name = name if name else company # ç„¡åˆ†å…¬å¸åå‰‡ç”¨å…¬å¸å
                    
                    # ç¯©é¸å°åŒ—å¸‚
                    if addr and display_name and ("å°åŒ—å¸‚" in addr or "è‡ºåŒ—å¸‚" in addr):
                        brand = detect_brand(company, name)
                        rows.append({"brand": brand, "name": display_name, "address": addr})
                except Exception as row_err: print(f"âš ï¸ è™•ç† CSV ç¬¬ {i+2} è¡Œæ™‚å‡ºéŒ¯: {row_err}")

    except FileNotFoundError: print(f"âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°ä¾†æº CSV æª”æ¡ˆ '{STORES_CSV_FILE}'"); return {"ok": False, "error": "Source CSV not found"}
    except UnicodeDecodeError: print(f"âŒ éŒ¯èª¤: CSV æª”æ¡ˆ '{STORES_CSV_FILE}' ç·¨ç¢¼éŒ¯èª¤ï¼Œè«‹ç¢ºä¿ç‚º UTF-8 æˆ– UTF-8-SIGã€‚"); return {"ok": False, "error": "CSV encoding error"}
    except Exception as e: print(f"âŒ è®€å– CSV æ™‚ç™¼ç”Ÿåš´é‡éŒ¯èª¤: {e}"); return {"ok": False, "error": f"CSV read error: {e}"}

    print(f"ğŸ” å°åŒ—å¸‚ä¾¿åˆ©å•†åº—åŸå§‹ç­†æ•¸ï¼š{len(rows)}")
    
    out_rows = []
    limit = len(rows) if not TAIPEI_BUILD_LIMIT else min(TAIPEI_BUILD_LIMIT, len(rows))
    print(f"â„¹ï¸ é–‹å§‹ Geocoding (ä¸Šé™ {limit} ç­†)...")
    
    # æª¢æŸ¥ API é‡‘é‘°æ˜¯å¦æœ‰æ•ˆï¼Œç„¡æ•ˆå‰‡è·³é Geocoding
    api_key_valid = GOOGLE_MAPS_API_KEY and not GOOGLE_MAPS_API_KEY.startswith("ã€è«‹åœ¨é€™è£¡")
    if not api_key_valid:
        print("âš ï¸ è­¦å‘Šï¼šæœªè¨­å®š Google API é‡‘é‘°ï¼Œç„¡æ³•é€²è¡Œ Geocodingï¼Œå°‡åªå„²å­˜åœ°å€ã€‚")

    for i, r in enumerate(rows[:limit]):
        if api_key_valid:
            coords = geocode(r["address"]) # ä½¿ç”¨å„ªåŒ–çš„ geocode
            if coords:
                out_rows.append({
                    "brand": r["brand"], "name": r["name"], "address": r["address"],
                    "lat": coords["lat"], "lng": coords["lng"]
                })
            # else: # å¯å–æ¶ˆè¨»è§£è§€å¯Ÿå¤±æ•—æƒ…æ³
            #     print(f"    - Geocode å¤±æ•— for {r['address']}")
        else:
             # ç„¡é‡‘é‘°æ™‚ï¼Œåªå„²å­˜åŸºæœ¬è³‡è¨Š (ä¸å«åº§æ¨™)
             out_rows.append({"brand": r["brand"], "name": r["name"], "address": r["address"], "lat": None, "lng": None})

        # é€²åº¦æç¤º (æ¯ 50 ç­†)
        if (i + 1) % 50 == 0:
            print(f"    ...å·²è™•ç† {i+1} / {limit} ç­†")

    # ã€ä¿®æ­£ã€‘å¯«å…¥é è™•ç†æª”æ¡ˆ
    try:
        with open(STORES_TAIPEI_CSV, "w", encoding="utf-8", newline="") as f:
            fieldnames = ["brand", "name", "address", "lat", "lng"]
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(out_rows)
        duration = time.time() - start_time
        print(f"âœ… å°åŒ—å¸‚ä¾¿åˆ©å•†åº—é è™•ç†å®Œæˆï¼šæˆåŠŸ Geocode {len([r for r in out_rows if r.get('lat')])} / {len(out_rows)} ç­† â†’ {STORES_TAIPEI_CSV}ã€‚è€—æ™‚ {duration:.2f} ç§’")
        return {"ok": True, "count": len(out_rows), "geocoded": len([r for r in out_rows if r.get('lat')])}
    except Exception as e:
        print(f"âŒ å„²å­˜é è™•ç†æª”æ¡ˆ {STORES_TAIPEI_CSV} å¤±æ•—: {e}")
        return {"ok": False, "error": f"Failed to write preprocessed CSV: {e}"}

# ---------------------------
# è³‡æ–™è¼‰å…¥ (æ‚¨çš„ç‰ˆæœ¬ï¼Œç¨ä½œå„ªåŒ–)
# ---------------------------
def load_taipei_stores():
    """ å¾é è™•ç†çš„ CSV è¼‰å…¥å°åŒ—å¸‚ä¾¿åˆ©å•†åº—è³‡æ–™ """
    if not os.path.exists(STORES_TAIPEI_CSV):
        print(f"â„¹ï¸ æœªæ‰¾åˆ°é è™•ç†æª”æ¡ˆ {STORES_TAIPEI_CSV}ï¼Œå˜—è©¦ç«‹å³å»ºç«‹...")
        build_result = ensure_taipei_stores() # å˜—è©¦å»ºç«‹
        if not build_result.get("ok") or not os.path.exists(STORES_TAIPEI_CSV):
             print(f"âŒ ç„¡æ³•å»ºç«‹æˆ–æ‰¾åˆ°é è™•ç†æª”æ¡ˆï¼Œä¾¿åˆ©å•†åº—åŠŸèƒ½å°‡ç„¡æ³•ä½¿ç”¨åº§æ¨™ã€‚")
             return [] # è¿”å›ç©ºåˆ—è¡¨

    stores = []
    try:
        with open(STORES_TAIPEI_CSV, "r", encoding="utf-8", newline='') as f:
            reader = csv.DictReader(f)
            if not reader.fieldnames: # è™•ç†ç©ºæª”æ¡ˆ
                 print(f"âš ï¸ é è™•ç†æª”æ¡ˆ {STORES_TAIPEI_CSV} ç‚ºç©ºã€‚")
                 return []
                 
            required_cols = ["name", "address", "lat", "lng"] # brand æ˜¯å¯é¸çš„
            if not all(col in reader.fieldnames for col in required_cols):
                 print(f"âŒ éŒ¯èª¤ï¼šé è™•ç†æª”æ¡ˆ {STORES_TAIPEI_CSV} ç¼ºå°‘å¿…è¦æ¬„ä½ {required_cols}ã€‚")
                 return []

            for r in reader:
                try:
                    # åªæœ‰åŒ…å«æœ‰æ•ˆç¶“ç·¯åº¦çš„è³‡æ–™æ‰åŠ å…¥
                    lat = float(r["lat"])
                    lng = float(r["lng"])
                    stores.append({
                        "brand": r.get("brand") or detect_brand(r.get("name", ""), ""), # å¦‚æœ brand æ¬„ä½ä¸å­˜åœ¨æˆ–ç‚ºç©ºï¼Œå˜—è©¦åµæ¸¬
                        "name": r["name"].strip(),
                        "address": r["address"].strip(),
                        "lat": lat,
                        "lng": lng
                    })
                except (ValueError, TypeError, KeyError) as row_err:
                    print(f"âš ï¸ è§£æé è™•ç†æª”æ¡ˆè¡Œå¤±æ•—: {row_err} - è³‡æ–™: {r}") # è·³éæ ¼å¼éŒ¯èª¤çš„è¡Œ
                    pass 
        print(f"ğŸ“¦ å°åŒ—å¸‚ä¾¿åˆ©å•†åº—è¼‰å…¥æˆåŠŸï¼š{len(stores)} ç­†")
    except FileNotFoundError:
         print(f"âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°é è™•ç†æª”æ¡ˆ {STORES_TAIPEI_CSV} (è¼‰å…¥éšæ®µ)") # ç†è«–ä¸Šä¸æ‡‰ç™¼ç”Ÿ
    except Exception as e:
        print(f"âŒ è®€å–é è™•ç†æª”æ¡ˆ {STORES_TAIPEI_CSV} æ™‚ç™¼ç”Ÿåš´é‡éŒ¯èª¤ï¼š{e}")
    return stores

def load_police():
    """ å¾ data.taipei API è¼‰å…¥è­¦å¯Ÿå±€è³‡æ–™ """
    try:
        print("â³ æ­£åœ¨å¾ data.taipei è¼‰å…¥è­¦å¯Ÿå±€è³‡æ–™...")
        r = requests.get(TAIPEI_POLICE_API_URL, timeout=15, verify=False) # ã€æ³¨æ„ã€‘æš«æ™‚å¿½ç•¥ SSL é©—è­‰
        r.raise_for_status()
        data = r.json()
        lst = data.get("result", {}).get("results", [])
        if not lst: print("âš ï¸ API å›å‚³çš„è­¦å¯Ÿå±€åˆ—è¡¨ç‚ºç©ºã€‚")
        print(f"âœ… è­¦å¯Ÿå±€è³‡æ–™è¼‰å…¥æˆåŠŸï¼š{len(lst)} ç­†")
        return lst
    except requests.exceptions.SSLError as ssl_err:
         print(f"âŒâŒâŒ è¼‰å…¥è­¦å¯Ÿå±€è³‡æ–™å¤±æ•— (SSLéŒ¯èª¤): {ssl_err}")
         print("   > å¯èƒ½æ˜¯ data.taipei æ†‘è­‰å•é¡Œæˆ–æœ¬æ©Ÿç¼ºå°‘æ ¹æ†‘è­‰ã€‚å·²å˜—è©¦å¿½ç•¥é©—è­‰ï¼Œè‹¥ä»å¤±æ•—è«‹æª¢æŸ¥ç¶²è·¯æˆ– API ç‹€æ…‹ã€‚")
         return []
    except Exception as e:
        print(f"âŒ è¼‰å…¥è­¦å¯Ÿå±€è³‡æ–™å¤±æ•—ï¼š{e}")
        return []

# --- ã€é‡è¦ã€‘ä¼ºæœå™¨å•Ÿå‹•æ™‚åŸ·è¡Œçš„å‹•ä½œ ---
print("==============================================")
print("ğŸš€ å•Ÿå‹• Guardian Light å¾Œç«¯ (æ‚¨çš„ç‰ˆæœ¬å„ªåŒ–)...")
print("==============================================")
# 1. è¼‰å…¥è­¦å¯Ÿå±€è³‡æ–™
POLICE_DATA = load_police() 
# 2. è¼‰å…¥ (æˆ–é è™•ç†) ä¾¿åˆ©å•†åº—è³‡æ–™
TAIPEI_STORES = load_taipei_stores() 
print("----------------------------------------------")

# ---------------------------
# API è·¯ç”± (æ‚¨çš„ç‰ˆæœ¬ï¼Œç¨ä½œå„ªåŒ–)
# ---------------------------
@app.route("/api/nearby")
def api_nearby():
    lat = request.args.get("lat")
    lng = request.args.get("lng")
    tp = request.args.get("type", "store") # æ”¹ç‚ºé è¨­ store
    brand_filter = request.args.get("brand", "")
    limit = int(request.args.get("limit", 10))

    if not lat or not lng: return jsonify({"error": "ç¼ºå°‘ lat æˆ– lng åƒæ•¸"}), 400

    print(f"\nğŸš€ æ”¶åˆ° /api/nearby è«‹æ±‚: lat={lat}, lng={lng}, type={tp}, brand={brand_filter}, limit={limit}")

    results = []
    if tp == "police":
        print(f"  > è™•ç†è­¦å¯Ÿå±€ (å…± {len(POLICE_DATA)} ç­†)...")
        processed_count = 0
        for item in POLICE_DATA: # å‡è¨­ POLICE_DATA å·²è¼‰å…¥
            name = item.get("name", "")
            addr = item.get("poi_addr") or item.get("display_addr")
            processed_count += 1
            if not addr: continue
            
            # å³æ™‚ Geocoding (ä½¿ç”¨å¿«å–)
            coords = geocode(addr) 
            if not coords: continue

            try:
                dist = get_distance(lat, lng, coords["lat"], coords["lng"])
                if dist != float("inf"):
                    results.append({
                        "brand": "è­¦å¯Ÿå±€", "name": name, "address": addr,
                        "lat": coords["lat"], "lng": coords["lng"], "distance": round(dist, 2)
                    })
            except Exception as dist_err:
                 print(f"âš ï¸ è¨ˆç®—è­¦å¯Ÿå±€ {name} è·é›¢æ™‚å‡ºéŒ¯: {dist_err}")
                 
            # å¯ä»¥åœ¨æ­¤åŠ å…¥è™•ç†ç­†æ•¸é™åˆ¶ï¼Œé¿å… Geocode éå¤š
            # if processed_count >= 300: break 

    elif tp == "store":
        print(f"  > è™•ç†ä¾¿åˆ©å•†åº— (å…± {len(TAIPEI_STORES)} ç­†)...")
        for item in TAIPEI_STORES: # ä½¿ç”¨é è™•ç†å¥½çš„è³‡æ–™
            # å¥—ç”¨å“ç‰Œç¯©é¸
            if brand_filter and brand_filter != "å…¨éƒ¨" and item["brand"] != brand_filter:
                continue
            
            try:
                dist = get_distance(lat, lng, item["lat"], item["lng"])
                # ç§»é™¤éé ç¯©é¸ (è·é›¢ç”±å‰ç«¯è™•ç†)
                # if dist > 30: continue 
                if dist != float("inf"):
                    results.append({
                        "brand": item["brand"], "name": item["name"], "address": item["address"],
                        "lat": item["lat"], "lng": item["lng"], "distance": round(dist, 2)
                    })
            except Exception as dist_err:
                 print(f"âš ï¸ è¨ˆç®—ä¾¿åˆ©å•†åº— {item.get('name')} è·é›¢æ™‚å‡ºéŒ¯: {dist_err}")
                 
    else:
        return jsonify({"error": "type åƒæ•¸åƒ…æ”¯æ´ police æˆ– store"}), 400

    if not results:
         print("â„¹ï¸ è™•ç†å®Œæˆï¼Œä½†é™„è¿‘æ²’æœ‰æ‰¾åˆ°ç¬¦åˆæ¢ä»¶çš„åœ°é»ã€‚")
         return jsonify([])

    print(f"  è¨ˆç®—å®Œæˆ {len(results)} ç­†æœ‰æ•ˆè³‡æ–™ï¼Œæ­£åœ¨æ’åº...")
    results.sort(key=lambda x: x["distance"])
    final_results = results[:min(limit, 50)] # å¥—ç”¨æ•¸é‡é™åˆ¶
    
    print(f"âœ… å®Œæˆï¼å›å‚³æœ€è¿‘çš„ {len(final_results)} ç­†çµæœã€‚")
    return jsonify(final_results)

@app.route("/api/brands")
def api_brands():
    """ å›å‚³æ‰€æœ‰ä¾¿åˆ©å•†åº—çš„å“ç‰Œèˆ‡æ•¸é‡ """
    from collections import Counter
    # è¨ˆç®—é è™•ç†è³‡æ–™ä¸­çš„å“ç‰Œ
    cnt = Counter([s.get("brand","å…¶ä»–") for s in TAIPEI_STORES])
    # å¢åŠ  "å…¨éƒ¨" é¸é …
    brands_dict = {"å…¨éƒ¨": len(TAIPEI_STORES)}
    brands_dict.update(dict(cnt))
    return jsonify({"brands": brands_dict, "total": len(TAIPEI_STORES)})

@app.route("/api/rebuild_stores")
def api_rebuild_stores():
    """ æ‰‹å‹•è§¸ç™¼é‡å»ºå°åŒ—å¸‚ä¾¿åˆ©å•†åº—é è™•ç†æª”æ¡ˆ """
    print("\nğŸ”¥ æ‰‹å‹•è§¸ç™¼é‡å»ºå°åŒ—å¸‚ä¾¿åˆ©å•†åº—è³‡æ–™...")
    out = ensure_taipei_stores() # åŸ·è¡Œé‡å»º
    global TAIPEI_STORES
    TAIPEI_STORES = load_taipei_stores() # é‡å»ºå¾Œç«‹åˆ»é‡æ–°è¼‰å…¥
    return jsonify({"ok": out.get("ok", False), "result": out, "loaded": len(TAIPEI_STORES)})

@app.route("/api/config")
def api_config():
    """ æä¾› Google Maps API Key çµ¦å‰ç«¯ """
    safe_key = GOOGLE_MAPS_API_KEY if GOOGLE_MAPS_API_KEY and not GOOGLE_MAPS_API_KEY.startswith("ã€è«‹åœ¨é€™è£¡") else ""
    return jsonify({"GOOGLE_MAPS_API_KEY": safe_key})

# ã€ç§»é™¤ã€‘ä¸å†éœ€è¦ç”± Flask æä¾›å‰ç«¯æª”æ¡ˆ
# @app.route("/nearby.html")
# def serve_nearby():
# Â  Â  return send_from_directory(PUBLIC_DIR, "nearby.html")

# ---------------------------
# å•Ÿå‹•ä¼ºæœå™¨
# ---------------------------
if __name__ == "__main__": 
Â  Â  print("\nğŸŒ ä¼ºæœå™¨æº–å‚™å°±ç·’ï¼Œé–‹å§‹ç›£è½è«‹æ±‚...")
Â  Â  # ä½¿ç”¨ host="0.0.0.0" è®“å€åŸŸç¶²è·¯å¯ä»¥é€£ç·š
Â  Â  # debug=True æ–¹ä¾¿é–‹ç™¼æ™‚è‡ªå‹•é‡è¼‰ï¼Œéƒ¨ç½²åˆ° Render æ™‚æ‡‰è€ƒæ…®é—œé–‰
Â  Â  app.run(debug=True, host="0.0.0.0", port=5001)
