# -*- coding: utf-8 -*-
import os, math, csv, json, requests
from flask import Flask, request, jsonify, send_from_directory, redirect
from flask_cors import CORS
from collections import defaultdict

# ---------------------------
# åŸºæœ¬è¨­å®š
# ---------------------------
app = Flask(__name__)
CORS(app)

PUBLIC_DIR = os.path.join(os.path.dirname(__file__), "public")
DATA_DIR = os.path.join(PUBLIC_DIR, "data")
os.makedirs(DATA_DIR, exist_ok=True)

STORES_CSV = os.path.join(DATA_DIR, "stores.csv")
STORES_TAIPEI_CSV = os.path.join(DATA_DIR, "stores_taipei.csv")
GEOCODE_CACHE_FILE = os.path.join(DATA_DIR, "geocode_cache.json")

GOOGLE_MAPS_API_KEY = os.environ.get("GOOGLE_MAPS_API_KEY", "")
GEOCODING_API_URL = "https://maps.googleapis.com/maps/api/geocode/json"
TAIPEI_POLICE_API_URL = "https://data.taipei/api/v1/dataset/a90ae184-c39e-4242-b2d6-d7a0403c0632?scope=resourceAquire"

TAIPEI_BUILD_LIMIT = None  # None = ä¸é™åˆ¶ç­†æ•¸

# ---------------------------
# å…¬ç”¨å‡½å¼
# ---------------------------
def get_distance(lat1, lon1, lat2, lon2):
    """çƒé¢è·é›¢ï¼ˆå…¬é‡Œï¼‰"""
    R = 6371.0
    try:
        lat1, lon1, lat2, lon2 = map(float, [lat1, lon1, lat2, lon2])
        dLat = math.radians(lat2 - lat1)
        dLon = math.radians(lon2 - lon1)
        a = math.sin(dLat / 2)**2 + math.cos(math.radians(lat1)) * math.cos(math.radians(lat2)) * math.sin(dLon / 2)**2
        return R * 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))
    except Exception:
        return float("inf")

def normalize_text(t: str) -> str:
    """å…¨å½¢è½‰åŠå½¢ + å»ç©ºç™½ + å°å¯«"""
    if not t:
        return ""
    # æŠŠå…¨å½¢å­—è½‰æˆåŠå½¢
    t = ''.join(
        chr(ord(c) - 0xFEE0) if 0xFF01 <= ord(c) <= 0xFF5E else c
        for c in t
    )
    # å»é™¤æ‰€æœ‰ç©ºç™½ã€è½‰æˆå°å¯«
    t = t.replace(" ", "").replace("ã€€", "").lower()
    return t

# ---------------------------
# Geocoding å¿«å–
# ---------------------------
if os.path.exists(GEOCODE_CACHE_FILE):
    with open(GEOCODE_CACHE_FILE, "r", encoding="utf-8") as f:
        GEO_CACHE = json.load(f)
else:
    GEO_CACHE = {}

def save_cache():
    with open(GEOCODE_CACHE_FILE, "w", encoding="utf-8") as f:
        json.dump(GEO_CACHE, f, ensure_ascii=False, indent=2)

# ---------------------------
# æ™ºæ…§ Geocodeï¼ˆå°ç£é™å®šï¼‰
# ---------------------------
def geocode(address: str):
    """æ™ºæ…§åŒ– Geocodeï¼ˆå«å¿«å–ã€æ¸…ç†æ¨“å±¤ã€é‡è©¦ã€å°ç£é™å®šï¼‰"""
    if not address:
        return None
    if address in GEO_CACHE:
        return GEO_CACHE[address]
    if not GOOGLE_MAPS_API_KEY:
        print("âš ï¸ æ²’æœ‰è¨­å®š GOOGLE_MAPS_API_KEYï¼Œè·³é geocode")
        return None

    clean = address.replace("ã€€", "").replace(" ", "")
    for token in ["åœ°ä¸‹ä¸€å±¤", "åœ°ä¸‹1æ¨“", "åœ°ä¸‹äºŒæ¨“", "B1", "B2", "B3", "1æ¨“", "2æ¨“", "3æ¨“", "4æ¨“", "5æ¨“", "6æ¨“"]:
        clean = clean.replace(token, "")
    for sep in ["ã€", "ï¼Œ", ","]:
        if sep in clean:
            clean = clean.split(sep)[0]
    clean = clean.replace("ä¹‹", "")

    def query_google(addr):
        try:
            r = requests.get(GEOCODING_API_URL, params={
                "address": addr,
                "key": GOOGLE_MAPS_API_KEY,
                "language": "zh-TW",
                "region": "tw",
                "components": "country:TW"
            }, timeout=8)
            r.raise_for_status()
            data = r.json()
            if data.get("status") == "OK" and data.get("results"):
                loc = data["results"][0]["geometry"]["location"]
                return {"lat": loc["lat"], "lng": loc["lng"]}
        except Exception as e:
            print(f"âŒ Geocode error: {addr} => {e}")
        return None

    coords = query_google(address) or query_google(clean)
    GEO_CACHE[address] = coords
    save_cache()
    return coords

def detect_brand(company: str) -> str:
    """æ›´æº–ç¢ºçš„å“ç‰Œåµæ¸¬"""
    if not company:
        return "å…¶ä»–"

    c = normalize_text(company.replace("è‚¡ä»½æœ‰é™å…¬å¸", ""))

    # é¿å…èª¤åˆ¤ï¼Œå…ˆåˆ¤æ–·æœ€ç‰¹æ®Šçš„
    if "çµ±ä¸€è¶…å•†" in c or "7-eleven" in c or "7_11" in c or "7ï¼11" in c or "7-11" in c:
        brand = "7-ELEVEN"
    elif "å…¨å®¶ä¾¿åˆ©å•†åº—" in c or "å…¨å®¶" in c:
        brand = "å…¨å®¶"
    elif "å…¨è¯ç¦åˆ©ä¸­å¿ƒ" in c or ("å…¨è¯" in c and "è¶…å•†" not in c):
        brand = "å…¨è¯"
    elif "èŠçˆ¾å¯Œ" in c or "hi-life" in c or "hilife" in c:
        brand = "èŠçˆ¾å¯Œ"
    elif "okä¾¿åˆ©" in c or "okmart" in c or "ok" in c:
        brand = "OKä¾¿åˆ©åº—"
    else:
        brand = "å…¶ä»–"

    print(f"âœ… åµæ¸¬å“ç‰Œ: {company} â†’ {brand}")
    return brand



def ensure_taipei_stores():
    if not os.path.exists(STORES_CSV):
        print("âš ï¸ æ‰¾ä¸åˆ° stores.csvï¼Œç„¡æ³•é‡å»º")
        return {"ok": False}

    rows = []
    with open(STORES_CSV, "r", encoding="utf-8") as f:
        reader = csv.DictReader(f)
        for row in reader:
            addr = (row.get("åˆ†å…¬å¸åœ°å€") or "").strip()
            company = (row.get("å…¬å¸åç¨±") or "").strip()
            name = (row.get("åˆ†å…¬å¸åç¨±") or "").strip()

            # åªæŠ“å°åŒ—å¸‚
            if ("å°åŒ—å¸‚" in addr) or ("è‡ºåŒ—å¸‚" in addr):
                brand = detect_brand(company) or detect_brand(name)
                print(f"âœ… åµæ¸¬å“ç‰Œ: {company} / {name} â†’ {brand}")
                rows.append({
                    "brand": brand,
                    "name": name or company,
                    "address": addr
                })

    print(f"ğŸ” å°åŒ—å¸‚ä¾¿åˆ©å•†åº—åŸå§‹ç­†æ•¸ï¼š{len(rows)}")

    out_rows = []
    limit = len(rows) if not TAIPEI_BUILD_LIMIT else min(TAIPEI_BUILD_LIMIT, len(rows))
    for r in rows[:limit]:
        coords = geocode(r["address"])
        if coords:
            out_rows.append({
                "brand": r["brand"],
                "name": r["name"],
                "address": r["address"],
                "lat": coords["lat"],
                "lng": coords["lng"],
            })

    with open(STORES_TAIPEI_CSV, "w", encoding="utf-8", newline="") as f:
        writer = csv.DictWriter(f, fieldnames=["brand", "name", "address", "lat", "lng"])
        writer.writeheader()
        writer.writerows(out_rows)

    print(f"âœ… å°åŒ—å¸‚ä¾¿åˆ©å•†åº—å®Œæˆï¼š{len(out_rows)} ç­† â†’ {STORES_TAIPEI_CSV}")
    return {"ok": True, "count": len(out_rows)}


def load_taipei_stores():
    if not os.path.exists(STORES_TAIPEI_CSV):
        return []
    stores = []
    with open(STORES_TAIPEI_CSV, "r", encoding="utf-8") as f:
        reader = csv.DictReader(f)
        has_brand = "brand" in (reader.fieldnames or [])
        for r in reader:
            brand = r.get("brand") if has_brand else detect_brand(r.get("name", ""))
            stores.append({
                "brand": brand or "å…¶ä»–",
                "name": r["name"],
                "address": r["address"],
                "lat": float(r["lat"]),
                "lng": float(r["lng"])
            })
    print(f"ğŸ“¦ å°åŒ—å¸‚ä¾¿åˆ©å•†åº—è¼‰å…¥ï¼š{len(stores)} ç­†")
    return stores

def load_police():
    local_file = os.path.join(DATA_DIR, "police.json")
    try:
        with open(local_file, "r", encoding="utf-8") as f:
            data = json.load(f)
            lst = data.get("result", {}).get("results", [])
            print(f"âœ… æœ¬åœ°è­¦å¯Ÿå±€è³‡æ–™è¼‰å…¥ï¼š{len(lst)} ç­†")
            return lst
    except Exception as e:
        print(f"âš ï¸ ç„¡æ³•è¼‰å…¥æœ¬åœ° police.jsonï¼š{e}")
        return []

POLICE_DATA = load_police()
TAIPEI_STORES = load_taipei_stores()

# ---------------------------
# API è·¯ç”±
# ---------------------------
@app.route("/")
def root_redirect():
    return redirect("/nearby.html", code=302)

@app.route("/api/nearby")
def api_nearby():
    lat = request.args.get("lat")
    lng = request.args.get("lng")
    tp = (request.args.get("type") or "").strip().lower()
    brand_filter = request.args.get("brand", "")
    limit = int(request.args.get("limit", 10))

    results = []

    # --- æ˜ç¢ºåˆ†æ”¯ ---
    if tp == "police":
        print("ğŸš“ æŸ¥è©¢è­¦å¯Ÿå±€è³‡æ–™ä¸­...")
        for it in POLICE_DATA:
            name = it.get("name", "")
            addr = it.get("poi_addr") or it.get("display_addr")
            coords = geocode(addr)
            if not coords:
                continue
            dist = get_distance(lat, lng, coords["lat"], coords["lng"])
            results.append({
                "brand": "è­¦å¯Ÿå±€",
                "name": name,
                "address": addr,
                "lat": coords["lat"],
                "lng": coords["lng"],
                "distance": round(dist, 2)
            })

    elif tp == "store":
        print(f"ğŸª æŸ¥è©¢ä¾¿åˆ©å•†åº—è³‡æ–™ä¸­... (å“ç‰Œç¯©é¸ï¼š{brand_filter})")
        match_count = 0
        for it in TAIPEI_STORES:
            # æ¯”å°å“ç‰Œï¼ˆç”¨ normalize_text ç¢ºä¿ä¸€è‡´ï¼‰
            brand1 = normalize_text(it["brand"])
            brand2 = normalize_text(brand_filter)
            print(f"ğŸ” æ¯”å°å“ç‰Œ: {it['brand']} vs {brand_filter}", end=" ")

            if brand_filter and brand_filter != "å…¨éƒ¨" and brand1 != brand2:
                print("âŒ")
                continue
            print("âœ…")

            dist = get_distance(lat, lng, it["lat"], it["lng"])
            if dist > 30:
                continue

            results.append({
                "brand": it["brand"],
                "name": it["name"],
                "address": it["address"],
                "lat": it["lat"],
                "lng": it["lng"],
                "distance": round(dist, 2)
            })
            match_count += 1

        print(f"ğŸ§® ç¯©é¸å¾Œå…± {match_count} ç­†ç¬¦åˆ {brand_filter}")

    else:
        print(f"âš ï¸ æœªçŸ¥çš„ type åƒæ•¸ï¼š{tp}")
        return jsonify({"error": "æœªçŸ¥çš„ type é¡åˆ¥ï¼Œè«‹ä½¿ç”¨ 'store' æˆ– 'police'"})

    # --- çµæœæ’åº + ä¿åº•è™•ç† ---
    results.sort(key=lambda x: x["distance"])
    if not results and tp == "store":
        print("âš ï¸ æ‰¾ä¸åˆ°ç¬¦åˆæ¢ä»¶çš„åº—ï¼Œå›å‚³å°åŒ—å¸‚æœ€è¿‘10é–“ï¼ˆä¿åº•ï¼‰")
        fallback = []
        for it in TAIPEI_STORES:
            dist = get_distance(lat, lng, it["lat"], it["lng"])
            it["distance"] = round(dist, 2)
            fallback.append(it)
        fallback.sort(key=lambda x: x["distance"])
        results = fallback[:10]

    return jsonify(results[:limit])




@app.route("/api/brands")
def api_brands():
    from collections import Counter
    cnt = Counter([s["brand"] for s in TAIPEI_STORES])
    return jsonify({"brands": dict(cnt), "total": len(TAIPEI_STORES)})

@app.route("/api/rebuild_stores")
def api_rebuild_stores():
    out = ensure_taipei_stores()
    global TAIPEI_STORES
    TAIPEI_STORES = load_taipei_stores()
    return jsonify({"ok": True, "result": out, "loaded": len(TAIPEI_STORES)})

@app.route("/api/config")
def api_config():
    return jsonify({"GOOGLE_MAPS_API_KEY": GOOGLE_MAPS_API_KEY})

# ---------------------------
# å®‰å…¨ï¼å±éšª ç†±åœ– API
# ---------------------------
DATA_LIGHTS = os.path.join(DATA_DIR, "lights.csv")
DATA_ACCIDENTS = os.path.join(DATA_DIR, "accidents.csv")
DATA_CRIME = os.path.join(DATA_DIR, "crime.csv")

_LAT_KEYS = ["lat", "latitude", "y", "ç·¯åº¦"]
_LNG_KEYS = ["lng", "lon", "longitude", "x", "ç¶“åº¦"]
_ADDR_KEYS = ["address", "åœ°å€", "åœ°é»", "ä½ç½®", "åœ°é»åç¨±"]

def _pick_col(d: dict, keys: list):
    for k in keys:
        if k in d and d[k]: return d[k]
        for kk in d.keys():
            if kk.strip().lower() == k: return d[kk]
    return None

def _to_float(x):
    try: return float(str(x).strip())
    except: return None

def _read_points_from_csv(filepath: str):
    pts = []
    if not os.path.exists(filepath):
        print(f"âš ï¸ æ‰¾ä¸åˆ°è³‡æ–™æª”ï¼š{filepath}")
        return pts

    # --- TWD97 TM2(121E) è½‰ WGS84 ---
    def twd97_to_wgs84(x, y):
        import math
        a = 6378137.0
        b = 6356752.314245
        lon0 = 121 * math.pi / 180
        k0 = 0.9999
        dx = 250000
        e = (1 - (b / a) ** 2) ** 0.5
        x -= dx
        M = y / k0
        mu = M / (a * (1 - e ** 2 / 4 - 3 * e ** 4 / 64 - 5 * e ** 6 / 256))
        e1 = (1 - (1 - e ** 2) ** 0.5) / (1 + (1 - e ** 2) ** 0.5)
        J1 = 3 * e1 / 2 - 27 * e1 ** 3 / 32
        J2 = 21 * e1 ** 2 / 16 - 55 * e1 ** 4 / 32
        J3 = 151 * e1 ** 3 / 96
        J4 = 1097 * e1 ** 4 / 512
        fp = mu + J1 * math.sin(2 * mu) + J2 * math.sin(4 * mu) + J3 * math.sin(6 * mu) + J4 * math.sin(8 * mu)
        e2 = (e * a / b) ** 2
        C1 = e2 * math.cos(fp) ** 2
        T1 = math.tan(fp) ** 2
        R1 = a * (1 - e ** 2) / ((1 - (e * math.sin(fp)) ** 2) ** 1.5)
        N1 = a / ((1 - (e * math.sin(fp)) ** 2) ** 0.5)
        D = x / (N1 * k0)
        Q1 = N1 * math.tan(fp) / R1
        Q2 = (D ** 2) / 2
        Q3 = (5 + 3 * T1 + 10 * C1 - 4 * C1 ** 2 - 9 * e2) * D ** 4 / 24
        Q4 = (61 + 90 * T1 + 298 * C1 + 45 * T1 ** 2 - 252 * e2 - 3 * C1 ** 2) * D ** 6 / 720
        lat = fp - Q1 * (Q2 - Q3 + Q4)
        Q5 = D
        Q6 = (1 + 2 * T1 + C1) * D ** 3 / 6
        Q7 = (5 - 2 * C1 + 28 * T1 - 3 * C1 ** 2 + 8 * e2 + 24 * T1 ** 2) * D ** 5 / 120
        lon = lon0 + (Q5 - Q6 + Q7) / math.cos(fp)
        return math.degrees(lat), math.degrees(lon)

    import csv
    for enc in ["utf-8-sig", "utf-8", "big5"]:
        try:
            with open(filepath, "r", encoding=enc) as f:
                rdr = csv.DictReader(f)
                for row in rdr:
                    # å»é™¤æ¬„ä½åç¨±ç©ºç™½
                    row = {k.strip(): v.strip() for k, v in row.items() if k}

                    # ---- äº¤é€šäº‹æ•…ï¼ˆåº§æ¨™-X/Yï¼‰----
                    if "åº§æ¨™-X" in row and "åº§æ¨™-Y" in row:
                        try:
                            lat = float(row["åº§æ¨™-Y"])
                            lng = float(row["åº§æ¨™-X"])
                            pts.append((lat, lng))
                            continue
                        except:
                            pass

                    # ---- è·¯ç‡ˆè³‡æ–™ï¼ˆTWD97X/Yï¼‰----
                    if "TWD97X" in row and "TWD97Y" in row:
                        try:
                            x = float(row["TWD97X"])
                            y = float(row["TWD97Y"])
                            lat, lng = twd97_to_wgs84(x, y)
                            pts.append((lat, lng))
                            continue
                        except Exception as e:
                            print(f"âš ï¸ TWD97 è½‰æ›å¤±æ•—ï¼š{e}")
                            continue

                    # ---- å…¶ä»–æ ¼å¼ ----
                    for k_lat, k_lng in [("lat", "lng"), ("Latitude", "Longitude"), ("ç·¯åº¦", "ç¶“åº¦")]:
                        if k_lat in row and k_lng in row:
                            try:
                                lat = float(row[k_lat])
                                lng = float(row[k_lng])
                                pts.append((lat, lng))
                                break
                            except:
                                continue
                break
        except Exception:
            continue

    print(f"ğŸ“¥ è®€å– {os.path.basename(filepath)}ï¼š{len(pts)} ç­†åº§æ¨™")
    return pts





def _grid_key(lat, lng, meters=150):
    lat_deg_per_m = 1.0 / 111_000.0
    lng_deg_per_m = 1.0 / (111_000.0 * max(0.00001, math.cos(math.radians(lat))))
    return (round(lat / (lat_deg_per_m * meters)), round(lng / (lng_deg_per_m * meters)))

def _accumulate(points, base_weight=1.0):
    bucket = defaultdict(float)
    center = {}
    for (lat, lng) in points:
        k = _grid_key(lat, lng)
        bucket[k] += base_weight
        center[k] = (lat, lng)
    maxw = max(bucket.values()) if bucket else 1.0
    out = []
    for k, w in bucket.items():
        c = center[k]
        out.append({"lat": c[0], "lng": c[1], "weight": round(w / maxw, 3)})
    return out

@app.route("/api/heatmap")
def api_heatmap():
    """å®‰å…¨åˆ†ç´šç†±åœ–è³‡æ–™ï¼šèåˆäº‹æ•…(å±éšª)èˆ‡è·¯ç‡ˆ(å®‰å…¨)"""
    limit = int(request.args.get("limit", 1000))

    # --- è®€å–ä¸‰ä»½è³‡æ–™ ---
    accidents = _read_points_from_csv(DATA_ACCIDENTS)
    lights = _read_points_from_csv(DATA_LIGHTS)

    if not accidents and not lights:
        return jsonify([])

    # --- çµ±åˆè³‡æ–™ ---
    import random
    danger_points = random.sample(accidents, min(limit, len(accidents)))
    safe_points = random.sample(lights, min(limit, len(lights)))

    # --- ç‚ºæ¯å€‹é»åŠ å…¥å®‰å…¨æŒ‡æ•¸ ---
    results = []
    for lat, lng in danger_points:
        results.append({"lat": lat, "lng": lng, "safety": -1})  # ç´…è‰²ï¼šå±éšª
    for lat, lng in safe_points:
        results.append({"lat": lat, "lng": lng, "safety": +1})  # ç¶ è‰²ï¼šå®‰å…¨

    print(f"ğŸ“¥ è®€å– accidents.csvï¼š{len(accidents)} ç­†åº§æ¨™")
    print(f"ğŸ“¥ è®€å– lights.csvï¼š{len(lights)} ç­†åº§æ¨™")
    print(f"ğŸ”¥ è¼¸å‡ºç´…={len(danger_points)} ç¶ ={len(safe_points)}")

    return jsonify(results)


@app.route("/nearby.html")
def serve_nearby():
    return send_from_directory(PUBLIC_DIR, "nearby.html")

@app.route("/heatmap.html")
def serve_heatmap():
    return send_from_directory(PUBLIC_DIR, "heatmap.html")

# ---------------------------
# å•Ÿå‹•ä¼ºæœå™¨
# ---------------------------
if __name__ == "__main__":
    print("ğŸš€ å•Ÿå‹• Guardian Light å¾Œç«¯ï¼ˆRender ç‰ˆï¼‰")
    port = int(os.environ.get("PORT", 5001))
    app.run(debug=False, host="0.0.0.0", port=port)
